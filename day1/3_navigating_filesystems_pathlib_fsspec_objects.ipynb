{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigating the Filesystem\n",
    "\n",
    "Let's delve into the essential skills of navigating and managing files and directories, a fundamental aspect of handling experimental data in neuroscience research. We will explore various commands and techniques to efficiently organize and access your experimental data, ensuring seamless integration into your analysis workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the Following Code to Get the Data for this Notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "paths = [\n",
    "    \"data/exp1/joey_2021-05-01_001/spikes.npy\", \n",
    "    \"data/exp1/joey_2021-05-02_001/spikes.npy\", \n",
    "    \"data/exp1/joey_2021-05-02_001/lfps.h5\", \n",
    "    \"data/exp1/phoebe_2021-05-02_001/spikes.npy\",\n",
    "    \"data/exp1/phoebe_2021-05-03_001/spikes.npy\", \n",
    "    \"data/exp1/phoebe_2021-05-03_001/lfps.h5\", \n",
    "    \"data/exp1/phoebe_2021-05-04_001/spikes.npy\",\n",
    "]\n",
    "\n",
    "for path in paths:\n",
    "    path = Path(path)\n",
    "    path.parent.mkdir(exist_ok=True, parents=True)\n",
    "    path.touch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the pathlib library\n",
    "\n",
    "The pathlib module in Python introduces an object-oriented approach to file system paths--. This section is designed to familiarize you with this powerful library, enhancing your ability to handle file paths and directories with more flexibility and intuitiveness. We'll cover basic operations like listing directories, globbing for pattern matching, and more, all through the lens of object-oriented programming.\n",
    "\n",
    "| Command | Purpose |\n",
    "| :-- | :-- |\n",
    "| `from pathlib import Path` | | \n",
    "| `Path('.').resolve()` | Gets the current working directory. |\n",
    "| `path = Path('./data')` | Make a `Path` object located in the data folder of the working directory. |\n",
    "| `list(path.iterdir())` | List all the files and folders in the specified path |\n",
    "| `new_path = path.joinpath(\"raw\")` | Append the \"/raw\" folder to the current path |\n",
    "| `new_path = path / \"raw\"` | Also append the \"/raw\" folder to the current path. |\n",
    "| `glob.glob('*.h5')` | Search for files that end in \".h5\" in the current path. |\n",
    "| `glob.glob('data*')` | Search for files that start with \"data\" in the current path. |\n",
    "| `glob.glob('./**/data*')` | Search for files that start with \"data\" in the any subfolder in the current path. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the current working directory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/iBOTS course/file_and_data_management/iBOTS-File-And-Data-Management/day1')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path() #creating a new path\n",
    "path.resolve()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What files and folders are inside the current working directory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('1_organizing-data-into-dictionaries.ipynb'),\n",
       " WindowsPath('2_parsing_metadata_from_filenames.ipynb'),\n",
       " WindowsPath('3_navigating_filesystems_pathlib_fsspec_objects.ipynb'),\n",
       " WindowsPath('4_webdav_sciebo.ipynb'),\n",
       " WindowsPath('data')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(path.iterdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What Files and folders are inside the \"data\" directory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('data/exp1/joey_2021-05-01_001'),\n",
       " WindowsPath('data/exp1/joey_2021-05-02_001'),\n",
       " WindowsPath('data/exp1/phoebe_2021-05-02_001'),\n",
       " WindowsPath('data/exp1/phoebe_2021-05-03_001'),\n",
       " WindowsPath('data/exp1/phoebe_2021-05-04_001')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathdata = Path('./data/exp1')\n",
    "pathdata\n",
    "list(pathdata.iterdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What Files and Folders are inside the \"exp1\" directory, inside the \"data\" directory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What folders in exp1 start with the subject \"phoebe\" (Hint: use Path().glob())?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('data/exp1/phoebe_2021-05-02_001'),\n",
       " WindowsPath('data/exp1/phoebe_2021-05-03_001'),\n",
       " WindowsPath('data/exp1/phoebe_2021-05-04_001')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pathdata.glob(\"*phoebe*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What folders in exp1 start with the subject \"joey\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('data/exp1/joey_2021-05-01_001'),\n",
       " WindowsPath('data/exp1/joey_2021-05-02_001')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pathdata.glob(\"*joey*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What folders in exp1 were recorded on the 2nd of May (hint-glob on the date part of the filename)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('data/exp1/joey_2021-05-02_001'),\n",
       " WindowsPath('data/exp1/phoebe_2021-05-02_001')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pathdata.glob(\"*05-02*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What files have the \".h5\" file extension (include all files in any subfolders of exp1)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('data/exp1/joey_2021-05-02_001/lfps.h5'),\n",
       " WindowsPath('data/exp1/phoebe_2021-05-03_001/lfps.h5')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pathdata.glob('./**/*.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What files have the \".npy\" file extension (include all files in any subfolders of exp1)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('data/exp1/joey_2021-05-01_001/spikes.npy'),\n",
       " WindowsPath('data/exp1/joey_2021-05-02_001/spikes.npy'),\n",
       " WindowsPath('data/exp1/phoebe_2021-05-02_001/spikes.npy'),\n",
       " WindowsPath('data/exp1/phoebe_2021-05-03_001/spikes.npy'),\n",
       " WindowsPath('data/exp1/phoebe_2021-05-04_001/spikes.npy')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pathdata.glob('./**/*.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of phoebe's files contain lfp data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('data/exp1/phoebe_2021-05-03_001/lfps.h5')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pathdata.glob('./*phoebe*/*lfp*')) #* * denotes anything inside a given folder/file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Remote File Systems using `fsspec`: \n",
    "\n",
    "In modern neuroscience research, accessing and manipulating data stored in remote file systems is increasingly common. This section introduces fsspec, a library for interacting with various file systems, including remote and cloud-based storage. We'll explore how to list, search, and manage files on different remote systems, an invaluable skill in a data-intensive field like neuroscience.\n",
    "\n",
    "\n",
    "| Code | Description |\n",
    "| :-- | :-- |\n",
    "|`fs.ls()` | Lists all files and directories in the current directory of the filesystem. |\n",
    "| `fs.glob('*.h5')` | Searches for files matching a specified pattern (in this case, all files ending with '.h5') in the current directory and subdirectories. |\n",
    "| `fs.makedirs()` | Creates a new directory at the specified path, including any necessary intermediate directories. |\n",
    "| `fs.removedirs()` | Removes directories recursively. Deletes a directory and, if it's empty, its parent directories as well. |\n",
    "| `fs.rm()` | Removes (deletes) a file or directory. |\n",
    "| `fs.read_text()`| Reads the contents of a file and returns it as a string. |\n",
    "| `fs.read_bytes()` | Reads the contents of a file and returns it as bytes. |\n",
    "| `fs.download()`| Downloads a file from the remote filesystem to the local filesystem. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GitHub Repos as a Remote Filesystem\n",
    "\n",
    "GitHub, a platform widely used for code sharing and collaboration, can also serve as a remote filesystem for data storage and retrieval. This section guides you through using GitHub repositories for accessing and managing data files, leveraging the `GithubFileSystem` class in `fsspec`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises**: Explore navigating remote GitHub filesystems using the `fsspec`'s `GithubFileSystem` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fsspecNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Downloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "   ---------------------------------------- 0.0/170.9 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 81.9/170.9 kB 2.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 163.8/170.9 kB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 170.9/170.9 kB 1.7 MB/s eta 0:00:00\n",
      "Installing collected packages: fsspec\n",
      "Successfully installed fsspec-2024.2.0\n"
     ]
    }
   ],
   "source": [
    "%pip install fsspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests)\n",
      "  Using cached charset_normalizer-3.3.2-cp311-cp311-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Using cached idna-3.6-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Using cached urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Using cached certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp311-cp311-win_amd64.whl (99 kB)\n",
      "Using cached idna-3.6-py3-none-any.whl (61 kB)\n",
      "Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Installing collected packages: urllib3, idna, charset-normalizer, certifi, requests\n",
      "Successfully installed certifi-2024.2.2 charset-normalizer-3.3.2 idna-3.6 requests-2.31.0 urllib3-2.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fsspec\n",
    "from fsspec.implementations.github import GithubFileSystem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: List all the files in the root directory of https://github.com/ibehave-ibots/iBOTS-Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['src/commit-scoreboard', 'src/workshop-registration']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fsspec.implementations.github import GithubFileSystem\n",
    "fs = GithubFileSystem(org=\"ibehave-ibots\", repo=\"iBOTS-Tools\")\n",
    "fs.ls('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all the files in the root directory of https://github.com/mwaskom/seaborn-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['README.md',\n",
       " 'anagrams.csv',\n",
       " 'anscombe.csv',\n",
       " 'attention.csv',\n",
       " 'brain_networks.csv',\n",
       " 'car_crashes.csv',\n",
       " 'dataset_names.txt',\n",
       " 'diamonds.csv',\n",
       " 'dots.csv',\n",
       " 'dowjones.csv',\n",
       " 'exercise.csv',\n",
       " 'flights.csv',\n",
       " 'fmri.csv',\n",
       " 'geyser.csv',\n",
       " 'glue.csv',\n",
       " 'healthexp.csv',\n",
       " 'iris.csv',\n",
       " 'mpg.csv',\n",
       " 'penguins.csv',\n",
       " 'planets.csv',\n",
       " 'png',\n",
       " 'process',\n",
       " 'raw',\n",
       " 'seaice.csv',\n",
       " 'taxis.csv',\n",
       " 'tips.csv',\n",
       " 'titanic.csv']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs = GithubFileSystem(org=\"mwaskom\", repo=\"seaborn-data\")\n",
    "fs.ls('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all the files whose filenames start with the letter \"p\" (i.e. \"glob\" the files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['healthexp.csv',\n",
       " 'mpg.csv',\n",
       " 'penguins.csv',\n",
       " 'planets.csv',\n",
       " 'png',\n",
       " 'process',\n",
       " 'tips.csv']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs.glob('*p*') #whatever word with p\n",
    "#fs.glob('p*') starts with p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all the files whose filenames end in the \"CSV\" extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anagrams.csv',\n",
       " 'anscombe.csv',\n",
       " 'attention.csv',\n",
       " 'brain_networks.csv',\n",
       " 'car_crashes.csv',\n",
       " 'diamonds.csv',\n",
       " 'dots.csv',\n",
       " 'dowjones.csv',\n",
       " 'exercise.csv',\n",
       " 'flights.csv',\n",
       " 'fmri.csv',\n",
       " 'geyser.csv',\n",
       " 'glue.csv',\n",
       " 'healthexp.csv',\n",
       " 'iris.csv',\n",
       " 'mpg.csv',\n",
       " 'penguins.csv',\n",
       " 'planets.csv',\n",
       " 'seaice.csv',\n",
       " 'taxis.csv',\n",
       " 'tips.csv',\n",
       " 'titanic.csv']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs.glob('*.csv') #ends with csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all the PNG image files in the \"png\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['png/img1.png',\n",
       " 'png/img2.png',\n",
       " 'png/img3.png',\n",
       " 'png/img4.png',\n",
       " 'png/img5.png',\n",
       " 'png/img6.png']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs.glob('png/*.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download all the PNG image files in the \"png\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "png_files = fs.glob('png/*.png')\n",
    "for file in png_files:\n",
    "    fs.download(file, file.split(\"/\")[-1]) #taking last element of list - img.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all the files in the root directory of the repo, with `detail=True` (i.e. `fs.ls(\"/\", detail=True)`).  What information does it give us about these files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'README.md',\n",
       "  'mode': '100644',\n",
       "  'type': 'file',\n",
       "  'size': 3101,\n",
       "  'sha': '453ab596a15d1f38f2514770783bda43d97ed755'},\n",
       " {'name': 'anagrams.csv',\n",
       "  'mode': '100644',\n",
       "  'type': 'file',\n",
       "  'size': 361,\n",
       "  'sha': '1d88d051b7fff295350bc2ed509b1946d41190b4'},\n",
       " {'name': 'anscombe.csv',\n",
       "  'mode': '100644',\n",
       "  'type': 'file',\n",
       "  'size': 556,\n",
       "  'sha': '62792b68fa5eed40eb75fe00e8daeaaf700f4f82'},\n",
       " {'name': 'attention.csv',\n",
       "  'mode': '100644',\n",
       "  'type': 'file',\n",
       "  'size': 1198,\n",
       "  'sha': '8d1f684e36f36aea05b10408c055eb4b30a3fcef'},\n",
       " {'name': 'brain_networks.csv',\n",
       "  'mode': '100644',\n",
       "  'type': 'file',\n",
       "  'size': 1075911,\n",
       "  'sha': '1ca1f474fa81aa8ee01654da5d6c9fd90c96fa27'},\n",
       " {'name': 'car_crashes.csv',\n",
       "  'mode': '100644',\n",
       "  'type': 'file',\n",
       "  'size': 3301,\n",
       "  'sha': '2248a441bfbbfb1d5c9fa7dbc9dae641c34829a1'},\n",
       " {'name': 'dataset_names.txt',\n",
       "  'mode': '100644',\n",
       "  'type': 'file',\n",
       "  'size': 174,\n",
       "  'sha': '2a27f085940eba05b41e87bbcc2d8c075c000831'},\n",
       " {'name': 'diamonds.csv',\n",
       "  'mode': '100644',\n",
       "  'type': 'file',\n",
       "  'size': 2772143,\n",
       "  'sha': '92259b40dbeea3165759a8f2cb576896612828ac'},\n",
       " {'name': 'dots.csv',\n",
       "  'mode': '100644',\n",
       "  'type': 'file',\n",
       "  'size': 25742,\n",
       "  'sha': '9b7eebf50146fd573b055b3b9f8d2caa57879723'},\n",
       " {'name': 'dowjones.csv',\n",
       "  'mode': '100644',\n",
       "  'type': 'file',\n",
       "  'size': 11349,\n",
       "  'sha': '8c35bf1355e823bd2aa119d2f4979c812e898df1'},\n",
       " {'name': 'exercise.csv',\n",
       "  'mode': '100644',\n",
       "  'type': 'file',\n",
       "  'size': 2735,\n",
       "  'sha': '28a6e946a50375555f67314f86d8d11aa2a4ff17'},\n",
       " {'name': 'flights.csv',\n",
       "  'mode': '100644',\n",
       "  'type': 'file',\n",
       "  'size': 2350,\n",
       "  'sha': '831265b40b19695dd9bd4f7c5bf4baa43c7b54b1'},\n",
       " {'name': 'fmri.csv',\n",
       "  'mode': '100644',\n",
       "  'type': 'file',\n",
       "  'size': 38329,\n",
       "  'sha': '5379a9f917d328baff09ff7140e396c44448eaba'},\n",
       " {'name': 'geyser.csv',\n",
       "  'mode': '100644',\n",
       "  'type': 'file',\n",
       "  'size': 4199,\n",
       "  'sha': 'bc7cafc5cf0200b0c92eae896534770fa25bb9f1'},\n",
       " {'name': 'glue.csv',\n",
       "  'mode': '100644',\n",
       "  'type': 'file',\n",
       "  'size': 2054,\n",
       "  'sha': 'af5c8c314c8906120ee626f47e830eef42e3745b'},\n",
       " {'name': 'healthexp.csv',\n",
       "  'mode': '100644',\n",
       "  'type': 'file',\n",
       "  'size': 7222,\n",
       "  'sha': 'a0602d1b18e82fb3bb44ddc79c8d9b53458544d5'},\n",
       " {'name': 'iris.csv',\n",
       "  'mode': '100644',\n",
       "  'type': 'file',\n",
       "  'size': 3858,\n",
       "  'sha': '20bd6ee57729baea0cc8b05397cc34eb4af8b452'},\n",
       " {'name': 'mpg.csv',\n",
       "  'mode': '100644',\n",
       "  'type': 'file',\n",
       "  'size': 21222,\n",
       "  'sha': '4013b0f0d4ac5bfb40381819ad76f926962192f1'},\n",
       " {'name': 'penguins.csv',\n",
       "  'mode': '100644',\n",
       "  'type': 'file',\n",
       "  'size': 13478,\n",
       "  'sha': '51fd0fe50c4e01e6f42e54063925571c004ef25a'},\n",
       " {'name': 'planets.csv',\n",
       "  'mode': '100644',\n",
       "  'type': 'file',\n",
       "  'size': 36263,\n",
       "  'sha': '337318354770d42471fd5ee21acd3deb40956f7c'},\n",
       " {'name': 'png',\n",
       "  'mode': '040000',\n",
       "  'type': 'directory',\n",
       "  'size': 0,\n",
       "  'sha': '99744314ccef8679fedcf29c33934f30512fd183'},\n",
       " {'name': 'process',\n",
       "  'mode': '040000',\n",
       "  'type': 'directory',\n",
       "  'size': 0,\n",
       "  'sha': '0015761099c99537288210a92dcef24f34eadddf'},\n",
       " {'name': 'raw',\n",
       "  'mode': '040000',\n",
       "  'type': 'directory',\n",
       "  'size': 0,\n",
       "  'sha': 'f2a72f6b359bc69099e4649eee56a5bb1a252a47'},\n",
       " {'name': 'seaice.csv',\n",
       "  'mode': '100644',\n",
       "  'type': 'file',\n",
       "  'size': 231046,\n",
       "  'sha': 'd68e9028569c8afff3a19fa558a37f245ff92cb2'},\n",
       " {'name': 'taxis.csv',\n",
       "  'mode': '100644',\n",
       "  'type': 'file',\n",
       "  'size': 869349,\n",
       "  'sha': 'ded045b462d361b8a0e5ddcdd6c3361cce4ddab4'},\n",
       " {'name': 'tips.csv',\n",
       "  'mode': '100644',\n",
       "  'type': 'file',\n",
       "  'size': 9729,\n",
       "  'sha': '1280a10886c1f858b29c1be1740619cdef3d6be1'},\n",
       " {'name': 'titanic.csv',\n",
       "  'mode': '100644',\n",
       "  'type': 'file',\n",
       "  'size': 57018,\n",
       "  'sha': '5ca531f5d70ce01e61bd7cf8b9f02b016dad4cd0'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs.ls(\"/\", detail=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and print the text contents of the \"anscombe.csv\" file. What data is inside this file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset,x,y\n",
      "I,10.0,8.04\n",
      "I,8.0,6.95\n",
      "I,13.0,7.58\n",
      "I,9.0,8.81\n",
      "I,11.0,8.33\n",
      "I,14.0,9.96\n",
      "I,6.0,7.24\n",
      "I,4.0,4.26\n",
      "I,12.0,10.84\n",
      "I,7.0,4.82\n",
      "I,5.0,5.68\n",
      "II,10.0,9.14\n",
      "II,8.0,8.14\n",
      "II,13.0,8.74\n",
      "II,9.0,8.77\n",
      "II,11.0,9.26\n",
      "II,14.0,8.1\n",
      "II,6.0,6.13\n",
      "II,4.0,3.1\n",
      "II,12.0,9.13\n",
      "II,7.0,7.26\n",
      "II,5.0,4.74\n",
      "III,10.0,7.46\n",
      "III,8.0,6.77\n",
      "III,13.0,12.74\n",
      "III,9.0,7.11\n",
      "III,11.0,7.81\n",
      "III,14.0,8.84\n",
      "III,6.0,6.08\n",
      "III,4.0,5.39\n",
      "III,12.0,8.15\n",
      "III,7.0,6.42\n",
      "III,5.0,5.73\n",
      "IV,8.0,6.58\n",
      "IV,8.0,5.76\n",
      "IV,8.0,7.71\n",
      "IV,8.0,8.84\n",
      "IV,8.0,8.47\n",
      "IV,8.0,7.04\n",
      "IV,8.0,5.25\n",
      "IV,19.0,12.5\n",
      "IV,8.0,5.56\n",
      "IV,8.0,7.91\n",
      "IV,8.0,6.89\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(fs.read_text(\"anscombe.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DeepLabCut**: Answer the following questions about the DeepLabCut GitHub Repo:   https://github.com/DeepLabCut/DeepLabCut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What files are in the root directory of the DeepLabCut repo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.circleci',\n",
       " '.codespellrc',\n",
       " '.github',\n",
       " '.gitignore',\n",
       " 'AUTHORS',\n",
       " 'CODE_OF_CONDUCT.md',\n",
       " 'CONTRIBUTING.md',\n",
       " 'LICENSE',\n",
       " 'NOTICE.yml',\n",
       " 'README.md',\n",
       " '_config.yml',\n",
       " '_toc.yml',\n",
       " 'conda-environments',\n",
       " 'deeplabcut',\n",
       " 'dlc.py',\n",
       " 'docker',\n",
       " 'docs',\n",
       " 'examples',\n",
       " 'reinstall.sh',\n",
       " 'requirements.txt',\n",
       " 'setup.py',\n",
       " 'tests',\n",
       " 'testscript_cli.py',\n",
       " 'tools']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs = GithubFileSystem(org=\"DeepLabCut\", repo=\"DeepLabCut\")\n",
    "fs.ls('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many files or folders are in the \"openfield-Pranav-2018-10-30\" folder, which is in the \"examples\" folder?  (Tip: the `len()` function can be helpful here.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fs.glob('examples/openfield-Pranav-2018-10-30/**'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many files are there, if you include every single file or folder in all the subfolders of the openfield example?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fs.glob('examples/openfield*/**'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download all the \"labeled-data\" files in the openfield example (`fs.download(recursive=True)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "png_files = fs.glob('png/*.png')\n",
    "for file in png_files:\n",
    "    fs.download(file, file.split(\"/\")[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "duckdb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
